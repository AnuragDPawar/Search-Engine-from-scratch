{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "input_path='files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to write individual file\n",
    "def generate_output_file(filename,output_dir_path,token_dict):\n",
    "    filename = 'out' + '-' + os.path.splitext(filename)[0]+'.txt'\n",
    "    filepath = os.path.join(output_dir_path, filename)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        for key, value in token_dict.items():\n",
    "            file.write(\"{} {}\\n\".format(key,value))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing each word from stopwords list to a dictionary to compare \n",
    "test_file = open('stopwords.txt','r',encoding='unicode_escape') \n",
    "stopwords_string = test_file.read()\n",
    "stopwards = dict(Counter(stopwords_string.split()))\n",
    "#preparing a dictionary for entire corpus\n",
    "global_test_file = open('out-gloabal_op_1.txt','r',encoding='unicode_escape') \n",
    "global_string = global_test_file.read()\n",
    "corpus = dict(Counter(global_string.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(time_intervals,final_time):\n",
    "    dfhm={}\n",
    "    i=0\n",
    "    input_path = 'files'\n",
    "    curr_time=0.0 #to hold the time\n",
    "    for file_n in os.listdir(input_path):\n",
    "        filepath = os.path.join(input_path, file_n)\n",
    "        start_time = time.time() #recording the time\n",
    "        myfile = open(filepath, 'r') \n",
    "        for line in myfile:\n",
    "            k, v = line.strip().split(' ')\n",
    "            item_k = k.strip()\n",
    "            item_v = int(v.strip())\n",
    "            dfhm[item_k] = 1+ dfhm.get(item_k,0) #taking global count for a particular key\n",
    "\n",
    "    for filename in os.listdir(input_path): #fetching each file\n",
    "        filepath = os.path.join(input_path, filename)\n",
    "        myfile = open(filepath, 'r')\n",
    "        curr_dict = {}\n",
    "        for line in myfile: #fetching key value from each file\n",
    "            k, v = line.strip().split(' ')\n",
    "            item_k = k.strip()\n",
    "            item_v = int(v.strip())\n",
    "            if item_k not in stopwards or len(item_k)>1: #checking conditions from preprocessing\n",
    "                curr_dict[item_k] = 1+ curr_dict.get(item_v,0)\n",
    "        myfile.close()\n",
    "        filename = 'out' + '-' + os.path.splitext(filename)[0]+'.txt' #file opened to write the data\n",
    "        filepath = os.path.join('output', filename)\n",
    "        with open(filepath, \"w\") as file:\n",
    "            for key, val in curr_dict.items():\n",
    "                tf= val/len(curr_dict) #calculating term frequency\n",
    "                df=dfhm[key] #document frequency\n",
    "                idf=math.log(503/df) #inverse document frequncy\n",
    "                tfidf=tf*idf \n",
    "                file.write(\"{} {}\\n\".format(key,tfidf))\n",
    "        file.close()\n",
    "        stop_time = time.time() - start_time #stopped recording time\n",
    "        curr_time += stop_time\n",
    "        if time_intervals and i+1 == time_intervals[0]:\n",
    "            final_time += curr_time\n",
    "            curr_time=0\n",
    "            print(\"Time taken for {} files: {}\".format(i+1,final_time)) #calculating the time\n",
    "            time_intervals.pop(0)\n",
    "        i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 50 files: 3.166135787963867\n",
      "Time taken for 100 files: 11.347270488739014\n",
      "Time taken for 150 files: 23.403220176696777\n",
      "Time taken for 200 files: 39.897759675979614\n",
      "Time taken for 250 files: 61.64963340759277\n",
      "Time taken for 300 files: 92.4275393486023\n",
      "Time taken for 350 files: 135.38487029075623\n",
      "Time taken for 400 files: 225.22013878822327\n",
      "Time taken for 450 files: 337.90827655792236\n",
      "Time taken for 500 files: 468.85254669189453\n"
     ]
    }
   ],
   "source": [
    "#to record the processing time\n",
    "time_intervals = [50,100,150,200,250,300,350,400,450,500]\n",
    "final_time=0.0\n",
    "preprocessing(time_intervals,final_time)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c1323188123de946c5b7b5e25c9bb76ffbaea461ceaf195e45c5d976a7611c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
